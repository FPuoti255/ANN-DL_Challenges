{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "vqa-model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA2UUvlrCnnQ"
      },
      "source": [
        "# Artifical Neural Networks & Deep Learning\r\n",
        "# Homework 3 - Visual Question Answering\r\n",
        "\r\n",
        "**Developement Team:**\r\n",
        "- Acquati Marco - 10583134 \r\n",
        "- Brugali Giorgio - 10794550\r\n",
        "- Puoti Francesco - 10595640 \r\n",
        "\r\n",
        "\r\n",
        "# *1. Data acquisition and augmentation*\r\n",
        "> We decide to not apply data augmentation since the data is big enough. We needed to split the loading of the images to deal with RAM upperbounds. The images were resized to 299 x 299 to comply with the expected input size of the Convolutional Neural Network we used for the images' features extraction.\r\n",
        "\r\n",
        "\r\n",
        "> **1.1.Tokenizer and word Embedding**\r\n",
        ">> For the sake of simplicity and clearness, all the comments are written **as the code flows** \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# *2. Model overview*\r\n",
        "\r\n",
        "\r\n",
        "> **2.1. The Network**\r\n",
        ">> It is composed by three main components:\r\n",
        "- Convolutional Neural Network (Inception V3) for image analysis and features extraction \r\n",
        "- Embedding layer + LSTM network to word analysis.\r\n",
        "- Classification part composed of a concatenation layer and of a Dense layer with softmax activation function.\r\n",
        "\r\n",
        "To be noticed is that we used also two dense layers (1024 neurons each), one after the Inception and the other one after the LSTM, with ReLU activation function layers.\r\n",
        "\r\n",
        "We also used: \r\n",
        "- Weight decay ( l2_norm )\r\n",
        "- Weight initialization ( he_normal since it works well with ReLu activation function)\r\n",
        "- Batch normalization between the dense layers and the ReLU layers\r\n",
        "\r\n",
        "\r\n",
        "> **2.2. Optimizer & LossFunction** \r\n",
        ">> - Adam, with a starting learning rate of 1e-4 and amsgrad = True to have an adaptive learning rate, so as to prevent the network from being stuck on a suboptimal solution.\r\n",
        ">> - Loss function : Sparse Categorical Crossentropy since we are dealing with integer numbers, not one-hot encoded.\r\n",
        "\r\n",
        "> **2.3. Further information about the implemention process**\r\n",
        ">> No EarlyStopping has been used in the final model as, after some trials, such model got stopped even though the learning process would have subsequently led to noteworthy improvements.\r\n",
        "\r\n",
        "> **2.4. Training Process**\r\n",
        ">> Number of epochs is set to 10, since we noticed that after this threshold, the network gets stuck in its accuracy and loss values without improvements.\r\n",
        "\r\n",
        ">>In order to preserve some RAM memory space we explicitly called the garbage collector and the del keyword for deleting the no more used images arrays.\r\n",
        "\r\n",
        ">> As aforementioned, we split the dataset to comply with RAM limits. In order to simulate the fitting process at the best, we iterates 10 times over the whole dataset that were being loaded split. \r\n",
        "We opted for this type of data loading, instead of using a custom dataset, since we found out that the first is much more faster then the latter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "EBt8FhXzCE-H"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for random operations. \n",
        "# This let our experiments to be reproducible. \n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED)  \n",
        "np.random.seed(SEED)\n",
        "cwd = os.getcwd()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DV1YM-M0CE-M"
      },
      "source": [
        "import json \n",
        "\n",
        "train_jsonLoad = json.load(open('../input/anndlo2020vqa/VQA_Dataset/train_questions_annotations.json', 'r'))\n",
        "test_jsonLoad = json.load(open('../input/anndlo2020vqa/VQA_Dataset/test_questions.json', 'r'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Zyi5SNIlCE-O"
      },
      "source": [
        "# At the loading time, we already compose the input and the target sequences by :\n",
        "#   1) Appending <EOS> to the source_sequence\n",
        "#   2) Prepending <go> and appending <eos> to obtain the target_sequence.\n",
        "\n",
        "def json_analyzer(json_, isTrain) :\n",
        "  X = []\n",
        "  for key in json_ :\n",
        "    image = os.path.join('../input/anndlo2020vqa/VQA_Dataset/Images/', (json_[key]['image_id']+'.png'))\n",
        "    question = json_[key]['question'] + ' <eos>'.lower().replace(\"/\" , \" \")\n",
        "\n",
        "    if isTrain :\n",
        "      answer = '<go> ' + json_[key]['answer'].lower() +' <eos>'     \n",
        "      X.append( (question, image, answer) ) \n",
        "      \n",
        "    else:\n",
        "      X.append( (question , image) )\n",
        "  return X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5pJMkHMbCE-Q"
      },
      "source": [
        "train = json_analyzer(train_jsonLoad, isTrain = True)\n",
        "train = np.array(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bLFiH2wBCE-R"
      },
      "source": [
        "question_idx = 0\n",
        "images_idx = 1\n",
        "answer_idx = 2\n",
        "\n",
        "#Converting to list is necessary since tokenizer works with list, but np array are handier\n",
        "train_questions = list(train[:, question_idx])\n",
        "train_answers = list(train [:, answer_idx])\n",
        "#there's no need for train_images to be converted to a list\n",
        "train_images = train[:, images_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1355SoytCE-V"
      },
      "source": [
        "MAX_QUESTION_WORD_LENGTH = 0\n",
        "MAX_ANSWER_WORD_LENGTH = 0\n",
        "QUESTION_WORDS = 0\n",
        "ANSWER_WORDS = 0 \n",
        "\n",
        "#QUESTIONS\n",
        "phrases = (train_questions)\n",
        "all_words= []\n",
        "\n",
        "# We used the following for loop to analyze the questions in order to find out which is the longest word \n",
        "# and the maximum number of words belonging the the question dataset.\n",
        "# This information will be used for the tokenizer.\n",
        "for p in phrases : \n",
        "  words_ = p.replace(\"?\" , \"\").split()\n",
        "  for w in words_ :\n",
        "    all_words.append(w)\n",
        "    MAX_QUESTION_WORD_LENGTH =  max(len(w), MAX_QUESTION_WORD_LENGTH)\n",
        "\n",
        "QUESTION_WORDS = len(np.unique(np.array(all_words)))\n",
        "\n",
        "#ANSWERS\n",
        "labels_dict = {\n",
        "        '0': 0,\n",
        "        '1': 1,\n",
        "        '2': 2,\n",
        "        '3': 3,\n",
        "        '4': 4,\n",
        "        '5': 5,\n",
        "        'apple': 6,\n",
        "        'baseball': 7,\n",
        "        'bench': 8,\n",
        "        'bike': 9,\n",
        "        'bird': 10,\n",
        "        'black': 11,\n",
        "        'blanket': 12,\n",
        "        'blue': 13,\n",
        "        'bone': 14,\n",
        "        'book': 15,\n",
        "        'boy': 16,\n",
        "        'brown': 17,\n",
        "        'cat': 18,\n",
        "        'chair': 19,\n",
        "        'couch': 20,\n",
        "        'dog': 21,\n",
        "        'floor': 22,\n",
        "        'food': 23,\n",
        "        'football': 24,\n",
        "        'girl': 25,\n",
        "        'grass': 26,\n",
        "        'gray': 27,\n",
        "        'green': 28,\n",
        "        'left': 29,\n",
        "        'log': 30,\n",
        "        'man': 31,\n",
        "        'monkey bars': 32,\n",
        "        'no': 33,\n",
        "        'nothing': 34,\n",
        "        'orange': 35,\n",
        "        'pie': 36,\n",
        "        'plant': 37,\n",
        "        'playing': 38,\n",
        "        'red': 39,\n",
        "        'right': 40,\n",
        "        'rug': 41,\n",
        "        'sandbox': 42,\n",
        "        'sitting': 43,\n",
        "        'sleeping': 44,\n",
        "        'soccer': 45,\n",
        "        'squirrel': 46,\n",
        "        'standing': 47,\n",
        "        'stool': 48,\n",
        "        'sunny': 49,\n",
        "        'table': 50,\n",
        "        'tree': 51,\n",
        "        'watermelon': 52,\n",
        "        'white': 53,\n",
        "        'wine': 54,\n",
        "        'woman': 55,\n",
        "        'yellow': 56,\n",
        "        'yes': 57,\n",
        "        '<go>' : 58,\n",
        "        '<eos>' : 59,\n",
        "        '<unk>' :60\n",
        "} \n",
        "\n",
        "\n",
        "\n",
        "# Notice that we increased of 1 the answers vocabulary values in order to use 0 as padding value.\n",
        "# Successively, when generating the CSV file, we substract 1 to recover the initial values\n",
        "# Initially, we tried to add a value in the answer_dictionary for the padding, as it has been done for '<go>' '<eos>' '<unk>'.\n",
        "# But, we noticed that different values for padding lead the network to worse results. Therefore, we opted for the solution above, \n",
        "# in order to have the same value for the questions padding as for the answers padding.\n",
        "for key in labels_dict :\n",
        "  MAX_ANSWER_WORD_LENGTH =  max(len(key), MAX_ANSWER_WORD_LENGTH)\n",
        "  labels_dict[key] += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8tdSPvpHCE-Y"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Create Tokenizer to convert words to integers\n",
        "# Replace out of vocabulary (OOV) tokens with <UNK>.\n",
        "questions_tokenizer = Tokenizer(num_words= QUESTION_WORDS, filters='?!,.\"/', oov_token = '<unk>')\n",
        "questions_tokenizer.fit_on_texts(train_questions)\n",
        "\n",
        "train_questions_tokenized = questions_tokenizer.texts_to_sequences(train_questions)\n",
        "\n",
        "questions_wtoi = questions_tokenizer.word_index\n",
        "\n",
        "answers_tokenizer = Tokenizer(oov_token = '<unk>', filters='?!,.\"/', num_words =len(labels_dict)) \n",
        "answers_tokenizer.word_index = labels_dict # This assignment is to use the given vocabulary for the answers\n",
        "answers_tokenized = answers_tokenizer.texts_to_sequences(train_answers)\n",
        "\n",
        "answers_wtoi = answers_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "knMb-UxpCE-a"
      },
      "source": [
        "#WE NEED THE SAME PADDING FOR QUESTION AND ANSWERS\n",
        "MAX_WORD_LENGTH = max(MAX_ANSWER_WORD_LENGTH, MAX_QUESTION_WORD_LENGTH)\n",
        "\n",
        "pad_train_questions = pad_sequences(train_questions_tokenized, maxlen=MAX_WORD_LENGTH, padding='post', value = 0)\n",
        "\n",
        "pad_answers = pad_sequences(answers_tokenized, maxlen=MAX_WORD_LENGTH, padding='post', value = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btm2441OCE-b"
      },
      "source": [
        "#  Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DeA8UjCnCE-c"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, ReLU, BatchNormalization, Softmax, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "import tensorflow.keras\n",
        "\n",
        "img_height = 299 \n",
        "img_width = 299\n",
        "\n",
        "\n",
        "initializer = tf.keras.initializers.he_normal(seed=SEED)\n",
        "regularizer = tf.keras.regularizers.l2(0.001) #weight decay\n",
        "\n",
        "# IMAGE FEATURE EXTRACTOR\n",
        "pre_trained_model = InceptionV3(include_top=False, weights='imagenet', input_shape = (img_height, img_width, 3))\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "img_features_extractor = Flatten()(pre_trained_model.output)\n",
        "\n",
        "img_features_extractor = Dense(1024,kernel_regularizer=regularizer, kernel_initializer = initializer)(img_features_extractor)\n",
        "img_features_extractor = BatchNormalization()(img_features_extractor)\n",
        "img_features_extractor = ReLU()(img_features_extractor)\n",
        "\n",
        "# LSTM FOR QUESTION EMBEDDING\n",
        "question_input = Input(shape=[MAX_QUESTION_WORD_LENGTH], dtype='int32')\n",
        "\n",
        "embedded_question = Embedding(input_dim=len(questions_wtoi) + 1, output_dim=64, input_length=MAX_QUESTION_WORD_LENGTH, mask_zero = True)(question_input)\n",
        "encoded_question = LSTM(512 ,input_shape=(None, ),return_sequences = True)(embedded_question)\n",
        "\n",
        "encoded_question = Dense(1024, kernel_regularizer=regularizer, kernel_initializer = initializer)(encoded_question)\n",
        "encoded_question = BatchNormalization()(encoded_question)\n",
        "encoded_question = ReLU()(encoded_question)\n",
        "\n",
        "# COMBINE CNN AND LSTM TO MAKE UP THE FINAL MODEL\n",
        "merged = tensorflow.keras.layers.Multiply()([img_features_extractor,encoded_question])\n",
        "merged = tensorflow.keras.layers.BatchNormalization()(merged)\n",
        "\n",
        "#OUTPUT CLASSIFICATION LAYER\n",
        "output = Dense(len(answers_wtoi)+1, activation = 'softmax')(merged)\n",
        "\n",
        "vqa_model = Model(inputs=[pre_trained_model.input, question_input], outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q0cQdyFrCE-f"
      },
      "source": [
        "vqa_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FuKBUzx4CE-h"
      },
      "source": [
        "loss = loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits= True)\n",
        "\n",
        "lr = 1e-4  # learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr, amsgrad=True)\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "# Compile Model\n",
        "vqa_model.compile(optimizer=optimizer, loss=loss, metrics=metrics )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0PxSQ7FuCE-i"
      },
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "SPLITS = 13\n",
        "\n",
        "def loadImages(list_, no_run):\n",
        "    gc.collect()\n",
        "    start = int((list_.shape[0]/SPLITS)*no_run)\n",
        "    end = int( (list_.shape[0]/SPLITS)*no_run+(list_.shape[0]/SPLITS) -1 )\n",
        "    no_data = end - start\n",
        "\n",
        "    print( 'Split n°: ' + str(no_run+1) + ' --> From index: ' + str(start) + ' to index: ' + str(end))\n",
        "\n",
        "    img_list = np.empty((no_data, img_height, img_width, 3) , dtype=np.float32)\n",
        "    q_list = np.empty((no_data, MAX_WORD_LENGTH), dtype=np.int32)\n",
        "    targets = np.empty((no_data, MAX_WORD_LENGTH), dtype=np.int32)\n",
        "    \n",
        "    k = 0;\n",
        "\n",
        "    for i in tqdm(range(start, end)):\n",
        "        targets[k] = (pad_answers[i])\n",
        "        img = PIL.Image.open(list_[i][images_idx])\n",
        "        img = img.convert('RGB')\n",
        "        img = img.resize((img_height, img_width), resample=Image.NEAREST)\n",
        "        img = np.array(img)  \n",
        "        img_list[k] = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "        q_list[k] = (list_[i][0])\n",
        "        k += 1\n",
        "    gc.collect()\n",
        "    return q_list, img_list, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jlWtx9CACE-j"
      },
      "source": [
        "train_valid_ = np.array(list(zip(pad_train_questions, np.array(train_images))))\n",
        "target = pad_answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cKyVOv0rCE-k"
      },
      "source": [
        "num_ep = 10\n",
        "bs = 32\n",
        "\n",
        "for ep in range(0, num_ep) :\n",
        "  for i in range(0, SPLITS) :\n",
        "    print('Epoch n°: ' + str(ep+1))\n",
        "    questions, imgages, targets = loadImages(train_valid_,i)\n",
        "    vqa_model.fit(x = [imgages, questions],\n",
        "                y = targets,\n",
        "                validation_split = 0.2,\n",
        "                epochs = 1,\n",
        "                batch_size = bs,\n",
        "                steps_per_epoch = (len(questions)*0.8)//bs,\n",
        "                validation_steps = (len(questions)*0.2)//bs,\n",
        "                verbose = 1\n",
        "                )\n",
        "    del questions \n",
        "    del imgages\n",
        "    del targets \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "P9DRPBdrCE-l"
      },
      "source": [
        "#--------------Saving the model---------------\n",
        "#---------------------------------------------\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "savedir ='./savedModels'\n",
        "\n",
        "if not os.path.exists(savedir):\n",
        "  os.makedirs(savedir) \n",
        "  \n",
        "savePath =  os.path.join(savedir, 'VQA_model' + datetime.now().strftime('%b%d_%H-%M-%S')+'.h5')\n",
        "vqa_model.save(savePath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b6WPe1kCE-n"
      },
      "source": [
        "# ***TESTING***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VfhngC5mCE-o"
      },
      "source": [
        "# This cell is used to select which model to train ( either one from those saved or the one just trained )\n",
        "\n",
        "# model = tf.keras.models.load_model('path_to_the_saved_model_to_use')\n",
        "model = vqa_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hxt1DbjmCE-p"
      },
      "source": [
        "def test_json_analyzer(json_) :\n",
        "  X = []\n",
        "  for key in json_ :\n",
        "    image = os.path.join('../input/anndlo2020vqa/VQA_Dataset/Images/', (json_[key]['image_id']+'.png'))\n",
        "    question = json_[key]['question'] + ' <eos>'.lower().replace(\"/\" , \" \")\n",
        "    X.append( (key, question , image) )\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cb-euh6oCE-q"
      },
      "source": [
        "test = test_json_analyzer(test_jsonLoad)\n",
        "test = np.array(test)\n",
        "\n",
        "id_idx = 0\n",
        "question_idx = 1\n",
        "images_idx = 2\n",
        "\n",
        "test_ids = test[:, id_idx]\n",
        "test_questions = list(test[:, question_idx])\n",
        "test_images = list(test[:, images_idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6Yheq5F4CE-r"
      },
      "source": [
        "test_questions_tokenized = questions_tokenizer.texts_to_sequences(test_questions)\n",
        "pad_test_questions = pad_sequences(test_questions_tokenized, maxlen=MAX_WORD_LENGTH, padding='post')\n",
        "\n",
        "test = np.array(list(zip(pad_test_questions, np.array(test_images))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Bo_sVVzgCE-t"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JywvnccOCE-t"
      },
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "img_height = 299\n",
        "img_width = 299\n",
        "\n",
        "def load_test_images(list_):\n",
        "    gc.collect()\n",
        "    no_data = list_.shape[0]\n",
        "\n",
        "    img_list = np.empty((no_data, img_height, img_width, 3) , dtype=np.float32)\n",
        "    q_list = np.empty((no_data, MAX_WORD_LENGTH), dtype=np.int32)\n",
        "    k = 0; # This parameter is needed to initialize values in empty np.arrays\n",
        "\n",
        "    for i in tqdm(range(0, no_data)):\n",
        "        img = PIL.Image.open(list_[i][1])\n",
        "        img = img.convert('RGB')\n",
        "        img = img.resize((img_height, img_width), resample=Image.NEAREST)\n",
        "        img = np.array(img)  \n",
        "        img_list[k] = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "        q_list[k] = (list_[i][0])\n",
        "        k += 1\n",
        "    gc.collect()\n",
        "    return q_list, img_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RkoDjUjCCE-u"
      },
      "source": [
        "questions, images = load_test_images(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_KMtdlKpCE-u"
      },
      "source": [
        "gc.collect()\n",
        "\n",
        "pred = model.predict(x=[images,questions])\n",
        "\n",
        "del questions\n",
        "del images\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "z8XWMYcjCE-v"
      },
      "source": [
        "\n",
        "def take_test_result(pred_) :\n",
        "  results = []\n",
        "  for k in pred_:\n",
        "    result = []\n",
        "    for i in k:\n",
        "      first = True\n",
        "      maxx = []\n",
        "      idx = 0\n",
        "      for j in i:\n",
        "        if first:\n",
        "          first = False\n",
        "          maxx = [j, idx]\n",
        "        if j > maxx[0]:\n",
        "          maxx = [j, idx]\n",
        "        idx += 1\n",
        "      result.append(maxx)\n",
        "    results.append(result)\n",
        "  return np.array(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "M0_cw2ixCE-v"
      },
      "source": [
        "results = take_test_result(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "C06fFL-nCE-w"
      },
      "source": [
        "def get_test_word(list_):\n",
        "  predicted_aswers = []\n",
        "  for k in list_:\n",
        "    predicted_asw = []\n",
        "    # k.shape = (20,2)\n",
        "    for el in k:\n",
        "      # el is the tuple ( probability , predicted word )\n",
        "      ch = int(el[1]) - 1 # now the pading value would be -1. This is where we recover the initial values of the dictionary.\n",
        "      if (ch!= -1) :\n",
        "        predicted_asw.append(ch)\n",
        "    predicted_aswers.append(predicted_asw)\n",
        "  return np.array(predicted_aswers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zvLMI1vKCE-w"
      },
      "source": [
        "answers = get_test_word(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RE2XxeZdCE-w"
      },
      "source": [
        "csv_results = []\n",
        "i=0\n",
        "for el in test_ids :\n",
        "  asw = answers[i][1]\n",
        "  csv_results.append(\n",
        "      [str(el), asw]\n",
        "      )\n",
        "  i+=1\n",
        "csv_results = np.array(csv_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZJSpgVMECE-x"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def create_csv(results, results_dir='./'):\n",
        "\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
        "\n",
        "        f.write('Id,Category\\n')\n",
        "\n",
        "        for el in results:\n",
        "            f.write(str(el[0])+ ',' + str(el[1]) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vE8i2S3fCE-x"
      },
      "source": [
        "create_csv(csv_results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}