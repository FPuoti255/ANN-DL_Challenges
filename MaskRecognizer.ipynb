{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaRLZtand-3o"
      },
      "source": [
        "# Artifical Neural Networks & Deep Learning\n",
        "# Homework 1 - Image Classification\n",
        "\n",
        "**Developement Team:**\n",
        "- Acquati Marco - 10583134 \n",
        "- Brugali Giorgio - 10794550\n",
        "- Puoti Francesco - 10595640 \n",
        "\n",
        "\n",
        "# *1. Data acquisition and augmentation*\n",
        "> This topic has been issued with annotations as the code flows down, to better clarify the correspondence between the explanations and the code snippets \n",
        "\n",
        "\n",
        "\n",
        "# *2. Model overview*\n",
        "\n",
        "\n",
        "> **2.1. Features' Extraction**\n",
        "\n",
        ">> The feature extractor is composed by *5 blocks*, each composed by:\n",
        "  - one convolutional part\n",
        "  - one  MaxPooling layer. \n",
        "\n",
        ">>The convolutional part has a variable number of convolutional layers: 2 Conv2D layers for the first two blocks and 3 Conv2D layers for the remaining ones.\n",
        "This choice was dictated with the intention of reducing the parameters' number in the network.\n",
        "\n",
        ">>Our idea was to start with small filters 3x3 because of the need to detail the features' extraction at the beginning. \n",
        "Afterwards, instead of increasing the filters' size, to avoid having possible distorted features that could result too effective in the learning process, we decided to augment the number of convolutional layers.\n",
        "\n",
        ">>Regarding the activation function, we chose the ReLU activation function as it is more suitable for the classification problem.\n",
        "BatchNormalization has been involved in the features' extraction part in order to both improve the stability of our network and to reduce covariance shift, the latter resulting in improving the training velocity as well. \n",
        "\n",
        ">>The pool size has been set to 3x3 with stride 2x2 to favor the overlapping: it has been demonstrated that the overlapping pooling areas reduce the likelihood of the network to overfit. \n",
        "\n",
        "> **2.2. BottleNeck Layer**\n",
        ">> In order to reduce the computational load of the network, \n",
        "the number of the features extractorâ€™s output channels is reduced by adding a 1x1 convolutional layer before feeding the output to the classifier.\n",
        "\n",
        "> **2.3. Classifier**\n",
        ">> - one flatten layer\n",
        ">> - two dense hidden layers with 2048 neurons each\n",
        ">> - the output layer with the SOFTMAX activation function and three classes\n",
        "\n",
        ">> It's worth highlighting the use of weight initialization (HeNormal distribution), which aims at improving the network speed, avoiding too many zeroes in the kernels at the beginning of the learning process.\n",
        "\n",
        ">> Moreover, weight decay has been implemented to reduce overfitting in the Dense layers.\n",
        "\n",
        ">> Both BatchNormalization and ReLU have been used for the same purpose as in the features' extraction part.\n",
        "\n",
        "> **2.4. Optimizer & LossFunction** \n",
        ">> - Adam, with a starting learning rate of 1e-3 and amsgrad = True to have an adaptive learning rate, so as to prevent the network from being stuck on a suboptimal solution.\n",
        ">> - Loss function : Categorical Crossentropy.\n",
        "\n",
        "> **2.5. Further information about the implemention process**\n",
        ">> No EarlyStopping has been used in the final model as, after some trials, such model got stopped even though the learning process would have subsequently led to noteworthy improvements.\n",
        "\n",
        ">> With regard to the checkpoints, we initially implemented them but, the more the network was becoming complex, the bigger was the space occupied on the HDD.\n",
        "Therefore, we need to avoid to use checkpoint, otherwise HDD space on kaggle as well as colab would have ran out of memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8UYrjc0gwSI"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39_gj0X1gz-E",
        "outputId": "cd42dea2-5a22-4452-e35a-f8adaf076ba6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW6qaot9g3jf",
        "outputId": "170aaa50-1c64-48d4-c56c-3357f0ee4934"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/My Drive/artificial-neural-networks-and-deep-learning-2020.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpMIKgL8g-qH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import operator\n",
        "\n",
        "# Since the training images were not divided in subfolders, \n",
        "#     we had to manage the data acquisition by means of data frame. \n",
        "# First, we acquired the images' paths an we sorted them in order to create \n",
        "#     a correspondence between each image and its label stored in the json file.\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "X = [] #list of images' paths\n",
        "for dirname, _, filenames in os.walk('/content/MaskDataset/training'):\n",
        "    filenames.sort()\n",
        "    for filename in filenames:\n",
        "           X.append(os.path.join(dirname, filename))\n",
        "\n",
        "with open('/content/MaskDataset/train_gt.json') as f:\n",
        "\n",
        " data = json.load(f)\n",
        " \n",
        " data = sorted(data.items(), key=operator.itemgetter(0))\n",
        "\n",
        "y = [] #list of target labels\n",
        "for i in range(len(data)):\n",
        "    y.append(str(data[i][1])) #il dataframe vuole delle string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkxcsgP1hAlq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# We decided to apply data augmentation on the training set not because of the data shortage\n",
        "# but in order to make our model more flexibile on recognizing objects in different positions and dimensions.\n",
        "#------------------------------------------------------------------------------------------------------------\n",
        "train_data_gen = ImageDataGenerator(rotation_range=10,\n",
        "                                    width_shift_range=10,\n",
        "                                    height_shift_range=10,\n",
        "                                    zoom_range=0.3,\n",
        "                                    horizontal_flip=True,\n",
        "                                    vertical_flip=True,\n",
        "                                    fill_mode='constant',\n",
        "                                    cval= 0,\n",
        "                                    rescale=1./255)\n",
        "\n",
        "# No data aumentation has been applied on validation set, since we want to have the images meant for validation \n",
        "# similar to the test images to find out the features of our model\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "valid_data_gen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxu1TGcuhCzE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Data set split in training and validation sets \n",
        "# with the latter having a size equal to the 20% of the entire data set.\n",
        "#-----------------------------------------------------------------------\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Generation of training and validation dataframes using pandas' library\n",
        "#------------------------------------------------------------------------\n",
        "dataframe_train = pd.DataFrame({\"input\": X_train, \"target\": y_train})    \n",
        "dataframe_valid = pd.DataFrame({\"input\": X_valid, \"target\": y_valid})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLy5l8PahHpI",
        "outputId": "adfe6253-2364-4abc-de27-5d46938b85f1"
      },
      "outputs": [],
      "source": [
        "# Batch size\n",
        "bs = 32\n",
        "\n",
        "# Images spatial shape\n",
        "img_h = 256\n",
        "img_w = 256\n",
        "\n",
        "num_classes = 3\n",
        "classes = ['0', '1', '2']\n",
        "clmode = \"rgb\"\n",
        "\n",
        "\n",
        "# Creation of the DataFrameIterators yielding tuples of (x, y) \n",
        "# where x is a numpy array containing a batch of images with shape (batch_size, *target_size, channels) \n",
        "# and y is a numpy array of corresponding labels.\n",
        "#------------------------------------------------------------------------------------------------------\n",
        "\n",
        "train_datagen = train_data_gen.flow_from_dataframe(\n",
        "      dataframe = dataframe_train,\n",
        "      directory = './',\n",
        "      x_col = \"input\",\n",
        "      y_col = \"target\",\n",
        "      target_size = (img_h, img_w),\n",
        "      color_mode = clmode,\n",
        "      classes = classes,\n",
        "      class_mode = \"categorical\",\n",
        "      batch_size = bs,\n",
        "      shuffle = True,\n",
        "      seed = SEED\n",
        ")\n",
        "\n",
        "valid_datagen = valid_data_gen.flow_from_dataframe(\n",
        "      dataframe = dataframe_valid,\n",
        "      directory = './',\n",
        "      x_col = \"input\",\n",
        "      y_col = \"target\",\n",
        "      target_size = (img_h, img_w),\n",
        "      color_mode = clmode,\n",
        "      classes = classes,\n",
        "      class_mode = \"categorical\",\n",
        "      batch_size = bs,\n",
        "      shuffle = True,\n",
        "      seed = SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqZx5_bmhIxV"
      },
      "outputs": [],
      "source": [
        "# Create Dataset objects\n",
        "# ----------------------\n",
        "\n",
        "# Training\n",
        "#---------\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: train_datagen,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes])) \n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "# Validation\n",
        "#-----------\n",
        "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_datagen, \n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n",
        "valid_dataset = valid_dataset.repeat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpYlOY3ap8zS"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "    \n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "depth = 5\n",
        "start_f = 64\n",
        "ker_sz = (3,3)\n",
        "ker_str = (1,1)\n",
        "pool_sz = (3,3)\n",
        "\n",
        "initializer = tf.keras.initializers.he_normal(seed=SEED)\n",
        "regularizer = tf.keras.regularizers.l2(0.001) #weight decay\n",
        "dpout = 0.5\n",
        "\n",
        "convNumb = 2\n",
        "\n",
        "# Features extraction\n",
        "# -------------------\n",
        "for i in range(depth):\n",
        "\n",
        "    if i == 0:\n",
        "        input_shape = [img_h, img_w, 3]\n",
        "    else:\n",
        "        input_shape=[None]\n",
        "        \n",
        "    if i == 2:\n",
        "        convNumb += 1 #increasing number of Conv2D layer in a block\n",
        "        \n",
        "    for j in range(convNumb):\n",
        "        model.add(tf.keras.layers.Conv2D(filters=start_f, \n",
        "                                 kernel_size=ker_sz,\n",
        "                                 strides=ker_str,\n",
        "                                 padding='same',\n",
        "                                 input_shape=input_shape))        \n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.ReLU())\n",
        "    model.add(tf.keras.layers.MaxPool2D(pool_sz, strides = 2))\n",
        "    if start_f < 512:\n",
        "        start_f *= 2\n",
        "\n",
        "#Bottle neck layer\n",
        "#-----------------\n",
        "model.add(tf.keras.layers.Conv2D(filters=start_f/2, \n",
        "                              kernel_size=(1,1),\n",
        "                              strides=ker_str,\n",
        "                              padding='same',\n",
        "                              input_shape=input_shape))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.ReLU())     \n",
        "\n",
        "#Classifier\n",
        "#----------\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(units=2048, \n",
        "                                kernel_regularizer = regularizer,\n",
        "                                kernel_initializer = initializer))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.ReLU()) \n",
        "model.add(tf.keras.layers.Dropout(dpout))\n",
        "model.add(tf.keras.layers.Dense(units=2048,\n",
        "                                kernel_regularizer=regularizer, \n",
        "                                kernel_initializer = initializer))\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, amsgrad=True), \n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(x=train_dataset,\n",
        "          epochs=150,\n",
        "          steps_per_epoch=len(train_datagen),\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=len(valid_datagen)\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBXj3_dfl7la"
      },
      "outputs": [],
      "source": [
        "#--------------Saving the model---------------\n",
        "#---------------------------------------------\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "savedir ='/content/drive/MyDrive/savedModels'\n",
        "\n",
        "if not os.path.exists(savedir):\n",
        "  os.makedirs(savedir) \n",
        "  \n",
        "savePath =  os.path.join(savedir, 'model' + datetime.now().strftime('%b%d_%H-%M-%S')+'.h5')\n",
        "model.save(savePath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkI56L5wia9E"
      },
      "outputs": [],
      "source": [
        "clmode = \"rgb\"\n",
        "source = '/content/MaskDataset/'\n",
        "\n",
        "test_data_gen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_datagen = test_data_gen.flow_from_directory(\n",
        "    source,\n",
        "    target_size = (256, 256),\n",
        "    color_mode = clmode,\n",
        "    classes =  [\"test\"],\n",
        "    class_mode = \"categorical\",\n",
        "    batch_size = 1,\n",
        "    shuffle = False\n",
        ")\n",
        "test_datagen.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYipu6tRiyH8"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict_generator(test_datagen, len(test_datagen), verbose = 1)\n",
        "result = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVwYrGjGi1J2"
      },
      "outputs": [],
      "source": [
        "import ntpath\n",
        "\n",
        "images = test_datagen.filenames\n",
        "i = 0\n",
        "\n",
        "for p in predictions:\n",
        "    prediction = np.argmax(p)\n",
        "    image_name = ntpath.basename(images[i])\n",
        "    result[image_name] = str(prediction)\n",
        "    i = i+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLEsTJy0i4k_"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def create_csv(results):\n",
        "\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "    with open(os.path.join('/content', csv_fname), 'w') as f:\n",
        "\n",
        "        f.write('Id,Category\\n')\n",
        "\n",
        "        for key, value in results.items():\n",
        "            f.write(key + ',' + str(value) + '\\n')\n",
        "    return csv_fname \n",
        "    # create_csv returns the path of the csv file, which is currently in the session folder, since google Drive rises an exception if we try to write a file              # directly in it. therefore, we first create the file and then, as it follows in the next cell, we move the csv file from the session folder to the drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NLNicqRi5PD"
      },
      "outputs": [],
      "source": [
        "file_to_move = create_csv(result)\n",
        "\n",
        "import shutil\n",
        "shutil.move(file_to_move, '/content/drive/MyDrive/') # moving the csv file"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BestMaskRecognizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.1 (main, Dec  8 2022, 11:38:20) [GCC 12.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
